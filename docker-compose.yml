
services:

  traefik:
    image: traefik:v2.11
    container_name: traefik
    command:
      - "--api.insecure=true"
      - "--providers.docker=true"
      - "--providers.docker.exposedByDefault=false"
      - "--entrypoints.web.address=:80"
    ports:
      - "80:80"
      - "8080:8080"
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
    networks:
      - backend-network

  db:
    image: josianamj/postgres_db:latest
    container_name: postgres
    build: 
        context: ./postgres2 
        dockerfile: Dockerfile
    restart: always
    environment:
       POSTGRES_USER: postgres
       POSTGRES_PASSWORD: password
       POSTGRES_DB: RestaurantDB
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "postgres", "-d", "RestaurantDB"]
      interval: 10s
      retries: 5
      start_period: 60s
      timeout: 5s
    networks:
      - backend-network   # Agregado aquí AGREGUÉ UN NET PORQUE NO ME  LEVANTA EL POSTGRESS.

  backend:
    build: 
        context: ./backend 
        dockerfile: Dockerfile  
    image: josianamj/backend_image:latest
    depends_on:
      db:
        condition: service_healthy
    networks:
      - backend-network   # Agregado aquí EL  NET ATTE PIKI ME CAGO EN TODO :3 
    labels: #veamos si hace routing este mae 
      - "traefik.enable=true"
      - "traefik.http.routers.backend.rule=PathPrefix(`/api`)"
      - "traefik.http.routers.backend.entrypoints=web"
      - "traefik.http.services.backend.loadbalancer.server.port=3000"

  redis:
    container_name: redis
    build:
      context: ./redis
      dockerfile: Dockerfile
    image: josianamj/redis_image:latest
    ports:
      - "6379:6379"
    expose:
      - "6379"
    networks:
      - backend-network

  charge-data:
    build: ./cargar_datos
    dns:
      - 8.8.8.8
    depends_on:
      db:
        condition: service_healthy
    environment:
        DB_USER: postgres
        DB_HOST: postgres
        DB_PASSWORD: password
        DB_NAME: RestaurantDB
        DB_PORT: 5432
    networks:
      - backend-network 

#----------------------------------------------------------------------|
#------------------------PROYECTO 2------------------------------------|
#----------------------------------------------------------------------|

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    volumes:
      - namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hive/hadoop-hive.env
    ports:
      - "50070:50070"
  
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    volumes:
      - datanode:/hadoop/dfs/data
    env_file:
      - ./hive/hadoop-hive.env
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    ports:
      - "50075:50075"
  
  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    env_file:
      - ./hive/hadoop-hive.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
    ports:
      - "10000:10000"
  
  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    env_file:
      - ./hive/hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432"
    ports:
      - "9083:9083"

  
  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
  
  presto-coordinator:
    image: shawnzhu/prestodb:0.181
    ports:
      - "8081:8081"
      
  airflow-webserver:
    image: apache/airflow:2.9.1
    container_name: airflow-webserver
    command: webserver
    ports:
      - "8082:8080"  # http://localhost:8082
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
    volumes:
      - ./dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts
      - ./airflow_db:/opt/airflow
    depends_on:
      - airflow-init

  airflow-scheduler:
    image: apache/airflow:2.9.1
    container_name: airflow-scheduler
    command: scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
    volumes:
      - ./dags:/opt/airflow/dags
      - ./airflow_db:/opt/airflow
    depends_on:
      - airflow-init

  airflow-init:
    image: apache/airflow:2.9.1
    container_name: airflow-init
    command: bash -c "airflow db init"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./airflow_db:/opt/airflow

  
volumes:
  namenode:
  datanode:

networks:
  backend-network:   # Nueva red agregada
    driver: bridge